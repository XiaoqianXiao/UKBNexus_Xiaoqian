{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "13d03f11a3623d9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import packages",
   "id": "bd9665f357e9a27a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pyspark\n",
    "import dxpy\n",
    "import dxdata"
   ],
   "id": "1677949a1ef879a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Spark initialization (Done only once; do not rerun this cell unless you select Kernel -> Restart kernel).\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ],
   "id": "d363c45111243788"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Automatically discover dispensed database name and dataset id\n",
    "dispensed_database = dxpy.find_one_data_object(\n",
    "    classname='database', \n",
    "    name='app*', \n",
    "    folder='/', \n",
    "    name_mode='glob', \n",
    "    describe=True)\n",
    "dispensed_database_name = dispensed_database['describe']['name']\n",
    "\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename='Dataset', \n",
    "    name='app*.dataset', \n",
    "    folder='/', \n",
    "    name_mode='glob')\n",
    "dispensed_dataset_id = dispensed_dataset['id']"
   ],
   "id": "9c8068e513c017e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Access dataset",
   "id": "2bcdfe85322ece45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = dxdata.load_dataset(id=dispensed_dataset_id)",
   "id": "ade106fcf3d38ae5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset 'entities' are virtual tables linked to one another.",
   "id": "738ecf33d072545a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.entities",
   "id": "3fb7cd98b2fbdc4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "participant = dataset['participant']",
   "id": "6b9fb4a08af9a770"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#field_names = ['eid', 'p31', 'p21022', 'p40005_i0', 'p93_i0_a0']",
   "id": "3956ec834dbaf35d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Looking up fields, given UKB showcase field id",
   "id": "5401e21b21f79a5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Returns all field objects for a given UKB showcase field id\n",
    "\n",
    "def fields_for_id(field_id):\n",
    "    from distutils.version import LooseVersion\n",
    "    field_id = str(field_id)\n",
    "    fields = participant.find_fields(name_regex=r'^p{}(_i\\d+)?(_a\\d+)?$'.format(field_id))\n",
    "    return sorted(fields, key=lambda f: LooseVersion(f.name))\n",
    "\n",
    "# Returns all field names for a given UKB showcase field id\n",
    "\n",
    "def field_names_for_id(field_id):\n",
    "    return [f.name for f in fields_for_id(field_id)]"
   ],
   "id": "4aa1b29b454cf6e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "field_ids = ['21003', '102']\n",
    "# sum flattens list of lists\n",
    "field_names = ['eid'] \\\n",
    "    + sum([field_names_for_id(field_id) for field_id in field_ids], [])"
   ],
   "id": "3521f20b8e9b1a19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Grabbing fields into a Spark DataFrame",
   "id": "c004408102877ed2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = participant.retrieve_fields(names=field_names, engine=dxdata.connect())",
   "id": "93419e13a0a86b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# See the first five entries as a Pandas DataFrame:\n",
    "df.limit(5).toPandas()"
   ],
   "id": "53eff615373ba2ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving results",
   "id": "1f3912235680afbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Saving as CSV file\n",
    "df.toPandas().to_csv('participants.csv', index=False)"
   ],
   "id": "9306198e419fddf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Writing results back to the project",
   "id": "ecebd7d602c225f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%bash\n",
    "dx upload participants.csv --dest /"
   ],
   "id": "787303e6e8cec16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
