{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:26:13.189675Z",
     "start_time": "2024-12-16T21:26:13.182022Z"
    }
   },
   "cell_type": "code",
   "source": "del list",
   "id": "e8b449e9734fbb45",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'list' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:08:00.085047Z",
     "start_time": "2024-12-16T17:08:00.081295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tian 1:10, 17:26\n",
    "subcortical_index = list(range(0,10)) + list(range(16,26))\n",
    "# Schaefer: \n",
    "# lh-mPFC: 199:205\n",
    "# rh-mPFC: 464:470\n",
    "# lh-Ins: 67, 108:111, 126:128\n",
    "# rh-Ins: 319, 361:364, 383:386\n",
    "## ACC: 390\n",
    "# Glasser\n",
    "cortical_roi = ['lh_dlPFC', 'rh_dlPFC', 'lh_mPFC', 'rh_mPFC', 'lh_PCC', 'rh_PCC', 'lh_Ins', 'rh_Ins']\n",
    "lh_dlPFC_index = [205, 246, 247, 249, 250, 252, 262, 263, 264, 265, 266, 276, 277]\n",
    "rh_dlPFC_index = [25, 66, 67, 69, 70, 72, 82, 83, 84, 85, 86, 96, 97]\n",
    "lh_mPFC_index = [236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 267, 343, 344, 345, 358, 359]\n",
    "rh_mPFC_index = [56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 87, 163, 164, 165, 178, 179]\n",
    "lh_PCC_index = [193, 194, 206, 209, 210, 211, 212, 213, 214, 300, 321, 340, 341]\n",
    "rh_PCC_index = [13, 14, 26, 29, 30, 31, 32, 33, 34, 120, 141, 160, 161]\n",
    "lh_Ins_index = [285, 287, 288, 289, 290, 291, 293, 294, 346, 347, 348, 357]\n",
    "rh_Ins_index = [105, 107, 108, 109, 110, 111, 113, 114, 166, 167, 168, 177]\n",
    "dic_cortical_roi = {\n",
    "    'lh_dlPFC': lh_dlPFC_index,\n",
    "    'rh_dlPFC': rh_dlPFC_index,\n",
    "    'lh_mPFC': lh_mPFC_index,\n",
    "    'rh_mPFC': rh_mPFC_index,\n",
    "    'lh_PCC': lh_PCC_index,\n",
    "    'rh_PCC': rh_PCC_index,\n",
    "    'lh_Ins': lh_Ins_index,\n",
    "    'rh_Ins': rh_Ins_index\n",
    "}"
   ],
   "id": "5fc54c0c71675a67",
   "outputs": [],
   "execution_count": 462
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T22:54:24.349693Z",
     "start_time": "2024-12-16T22:54:24.342793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "# === Step 1: Define Functions === #\n",
    "\n",
    "def load_dataset(base_dir, data_set):\n",
    "    \"\"\"\n",
    "    Load dataset-specific files.\n",
    "    \"\"\"\n",
    "    fMRIinfo_file_path = os.path.join(base_dir, f\"{data_set}_data_set.csv\")\n",
    "    participant_file_path = os.path.join(base_dir, \"participants_fMRI.csv\")\n",
    "    return pd.read_csv(fMRIinfo_file_path), pd.read_csv(participant_file_path)\n",
    "\n",
    "\n",
    "def load_subject_timeseries(subject_ID, session_ID, derivatives_dir):\n",
    "    \"\"\"\n",
    "    Load cortical and subcortical timeseries data for a subject.\n",
    "    \"\"\"\n",
    "    cortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Glasser.csv.gz\"\n",
    "    cortical_file_path = os.path.join(derivatives_dir, \"timeseries\", cortical_file_name)\n",
    "\n",
    "    subcortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Tian_Subcortex_S2_3T.csv.gz\"\n",
    "    subcortical_file_path = os.path.join(derivatives_dir, \"timeseries\", subcortical_file_name)\n",
    "\n",
    "    if not (os.path.exists(cortical_file_path) and os.path.exists(subcortical_file_path)):\n",
    "        print(f\"Missing files for subject {subject_ID}, session {session_ID}.\")\n",
    "        return None\n",
    "\n",
    "    # Load and process cortical timeseries\n",
    "    df_cortical_all = pd.read_csv(cortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "\n",
    "    # Load and process subcortical timeseries\n",
    "    df_subcortical_all = pd.read_csv(subcortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "\n",
    "    # Combine cortical and subcortical ROIs\n",
    "    return pd.concat([df_cortical_all.transpose(), df_subcortical_all.transpose()], axis=1)\n",
    "\n",
    "def add_noise_to_constant_features(data, noise_level=0.01):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to constant features (std = 0) instead of removing them,\n",
    "    and replace them in the data matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: numpy.ndarray\n",
    "        Input data matrix (rows: observations, columns: features).\n",
    "    - noise_level: float\n",
    "        Standard deviation of the Gaussian noise to add to constant features.\n",
    "    \n",
    "    Returns:\n",
    "    - data_with_noise: numpy.ndarray\n",
    "        Data matrix with constant features replaced by their noised versions.\n",
    "    \"\"\"\n",
    "    # Identify constant features (standard deviation = 0 across rows)\n",
    "    constant_features = np.where(np.std(data, axis=0) == 0)[0]\n",
    "    \n",
    "    # Log constant feature indices\n",
    "    print(f\"Identifying constant features to replace with noise at indices: {constant_features}\")\n",
    "\n",
    "    # Generate Gaussian noise for constant features\n",
    "    noisy_data = data.copy()\n",
    "    if constant_features.size > 0:\n",
    "        noisy_data[:, constant_features] = np.random.normal(0, noise_level, \n",
    "                                                               size=(data.shape[0], len(constant_features)))\n",
    "    \n",
    "    return noisy_data\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Handle missing values and replace constant features with noise.\n",
    "    This ensures there are no NaNs left in the data.\n",
    "    \"\"\"\n",
    "    # Handle missing values (replace NaNs with column mean)\n",
    "    data_filled = np.copy(data)\n",
    "    for j in range(data.shape[1]):\n",
    "        if np.isnan(data[:, j]).any():\n",
    "            column_mean = np.nanmean(data[:, j])  # Compute column mean\n",
    "            if not np.isnan(column_mean):  # Ensure it's a valid mean\n",
    "                data_filled[:, j] = np.nan_to_num(data[:, j], nan=column_mean)\n",
    "\n",
    "    # Add noise to constant features\n",
    "    #data_filled_noisy = add_noise_to_constant_features(data_filled, noise_level=0.05)\n",
    "    data_filled_noisy = data_filled\n",
    "    # Verify that no NaNs remain\n",
    "    # if np.isnan(data_filled_noisy).any():\n",
    "    #     print(\"Warning: NaNs still exist in data after cleaning.\")\n",
    "    # else:\n",
    "    #     print(\"No NaNs present after cleaning.\")\n",
    "\n",
    "    return data_filled_noisy\n",
    "\n",
    "\n",
    "def compute_connectivity(data):\n",
    "    \"\"\"\n",
    "    Compute connectivity matrix for the given time series data.\n",
    "    \"\"\"\n",
    "    correlation_measure = ConnectivityMeasure(kind=\"correlation\")\n",
    "    return correlation_measure.fit_transform([data])[0]\n",
    "\n",
    "\n",
    "def extract_upper_triangle(matrix):\n",
    "    \"\"\"\n",
    "    Extract the upper triangle values (excluding diagonal) from a connectivity matrix.\n",
    "    \"\"\"\n",
    "    upper_tri_indices = np.triu_indices(matrix.shape[0], k=1)\n",
    "    return matrix[upper_tri_indices]\n",
    "\n",
    "\n",
    "# === Step 2: Define the Pipeline === #\n",
    "\n",
    "def process_fMRI_subject(subject_ID, session_ID, derivatives_dir):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing a single subject's fMRI data.\n",
    "    \"\"\"\n",
    "    # Load subject timeseries\n",
    "    df_roi = load_subject_timeseries(subject_ID, session_ID, derivatives_dir)\n",
    "    if df_roi is None:\n",
    "        return None, None\n",
    "\n",
    "    # Clean data\n",
    "    cleaned_data = clean_data(df_roi.values)\n",
    "    # Check NaNs again before standardization\n",
    "    if np.isnan(cleaned_data).any():\n",
    "        print(f\"Error: NaNs found in cleaned data for subject {subject_ID}\")\n",
    "        return None, None\n",
    "    # Standardize data\n",
    "    #standardized_data = StandardScaler().fit_transform(df_roi.values)\n",
    "    standardized_data = StandardScaler().fit_transform(cleaned_data)\n",
    "\n",
    "    # Compute connectivity matrix\n",
    "    connectivity_matrix = compute_connectivity(standardized_data)\n",
    "\n",
    "    # Extract upper triangle\n",
    "    upper_triangle = extract_upper_triangle(connectivity_matrix)\n",
    "\n",
    "    return upper_triangle, subject_ID\n",
    "\n",
    "\n",
    "def process_fMRI_data(data_set, user_dir, project_name, session_ID):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing fMRI data for all subjects.\n",
    "    \"\"\"\n",
    "    # Set paths\n",
    "    base_dir = os.path.join(user_dir, project_name, \"data\")\n",
    "    derivatives_dir = os.path.join(base_dir, \"derivatives\")\n",
    "\n",
    "    # Load dataset\n",
    "    df_fMRIinfo, df_participants = load_dataset(base_dir, data_set)\n",
    "    subject_IDs = df_fMRIinfo[\"eid\"].unique()\n",
    "\n",
    "    # Initialize lists for data\n",
    "    connectivity_data = []\n",
    "    subject_ids_cleaned = []\n",
    "\n",
    "    # Process each subject individually\n",
    "    for subject_ID in subject_IDs:\n",
    "        upper_triangle, cleaned_subject_ID = process_fMRI_subject(\n",
    "            subject_ID, session_ID, derivatives_dir\n",
    "        )\n",
    "        if upper_triangle is not None:\n",
    "            connectivity_data.append(upper_triangle)\n",
    "            subject_ids_cleaned.append(cleaned_subject_ID)\n",
    "\n",
    "    # Filter participants based on available data\n",
    "    df_filtered = df_participants.loc[df_participants[\"eid\"].isin(subject_ids_cleaned)]\n",
    "\n",
    "    return np.array(connectivity_data), df_filtered\n"
   ],
   "id": "c2c46bdad1394cae",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T00:39:35.914345Z",
     "start_time": "2024-12-17T00:39:35.893361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#codes for modeling\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Ensure binary target\n",
    "def ensure_binary_target(y):\n",
    "    unique_values = np.unique(y)\n",
    "    if len(unique_values) > 2:\n",
    "        raise ValueError(\"Target variable contains more than two classes. Please preprocess the data.\")\n",
    "    if unique_values.dtype == bool:\n",
    "        return y.astype(int)\n",
    "    elif set(unique_values) == {0, 1} or set(unique_values) == {1, 0}:\n",
    "        return y\n",
    "    else:\n",
    "        raise ValueError(\"Target variable is not binary. Please preprocess the data.\")\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "\n",
    "# Model selection using cross-validation\n",
    "def model_selection(X_train, y_train):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),  # Provides coefficients (coef_)\n",
    "        \"Ridge Classifier\": LogisticRegression(penalty='l2', solver='liblinear'),  # coef_\n",
    "        \"Lasso (L1)\": LogisticRegression(penalty='l1', solver='liblinear'),  # coef_\n",
    "        \"LDA\": LinearDiscriminantAnalysis(),  # Provides coefficients (coef_)\n",
    "        \"Perceptron\": Perceptron(),  # Provides coefficients (coef_)\n",
    "        \"SVM (Linear)\": SVC(kernel='linear'),  # Provides coefficients (coef_) when kernel='linear'\n",
    "        \"Random Forest\": RandomForestClassifier(),  # Provides feature_importances_\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "    best_name = \"\"\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "        print(f\"Model: {model_name}, CV Score: {cv_score:.4f}\")\n",
    "\n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            best_model = model\n",
    "            best_name = model_name\n",
    "\n",
    "    print(f\"Best Model: {best_name} with CV score: {best_score:.4f}\")\n",
    "    return best_model, best_name\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "def feature_selection_with_rfe(X_train, y_train, n_features, best_model):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE, with fallback to univariate selection for models without coefficients.\n",
    "    \"\"\"\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        # Use RFE for models with coefficients or feature importances\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=n_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = rfe.support_\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using RFE. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    else:\n",
    "        # Fallback to univariate feature selection\n",
    "        print(\"Model lacks coefficients/feature importance; using univariate feature selection.\")\n",
    "        \n",
    "        # Use SelectKBest with F-statistic (or mutual information if preferred)\n",
    "        selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = selector.get_support()\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using univariate method. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def feature_selection_with_rfe_cv(X_train, y_train, best_model, scoring_metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE or univariate selection, optimizing the number of features automatically\n",
    "    using cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def evaluate_features(model, X, y, num_features):\n",
    "        \"\"\"\n",
    "        Helper function to evaluate the model's performance with the given number of features using cross-validation.\n",
    "        \"\"\"\n",
    "        if hasattr(model, \"coef_\") or hasattr(model, \"feature_importances_\"):\n",
    "            # Perform RFE with the given number of features\n",
    "            rfe = RFE(estimator=model, n_features_to_select=num_features, step=1)\n",
    "            X_selected = rfe.fit_transform(X, y)\n",
    "        else:\n",
    "            # Use univariate feature selection as a fallback\n",
    "            selector = SelectKBest(score_func=f_classif, k=num_features)\n",
    "            X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "        # Evaluate model performance using cross-validation\n",
    "        scores = cross_val_score(model, X_selected, y, cv=5, scoring=scoring_metric)\n",
    "        return scores.mean()\n",
    "\n",
    "    # Iterate over a range of features to find the optimal number of features\n",
    "    best_score = -np.inf\n",
    "    optimal_num_features = 0\n",
    "    for num_features in range(1, X_train.shape[1] + 1):\n",
    "        score = evaluate_features(best_model, X_train, y_train, num_features)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            optimal_num_features = num_features\n",
    "\n",
    "    print(f\"Optimal number of features: {optimal_num_features} with cross-validated score: {best_score:.4f}\")\n",
    "\n",
    "    # Perform final RFE or univariate selection with the optimal number of features\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=optimal_num_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = rfe.support_\n",
    "    else:\n",
    "        selector = SelectKBest(score_func=f_classif, k=optimal_num_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = selector.get_support()\n",
    "\n",
    "    return selected_features, optimal_num_features\n",
    "\n",
    "\n",
    "# Two-step grid search for hyperparameter optimization\n",
    "def tune_model_hyperparameters(model, model_name, X_train, y_train):\n",
    "    refined_grid = {}  # Initialize with a default value to avoid \"unbound variable\" error\n",
    "\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Ridge Classifier\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Lasso (L1)\" or model_name == \"ElasticNet (L1+L2)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"SVM (Linear)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        broad_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "    elif model_name == \"Perceptron\":\n",
    "        broad_param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "    elif model_name == \"LDA\":\n",
    "        broad_param_grid = {'shrinkage': [None, 'auto'], 'solver': ['svd', 'lsqr', 'eigen']}\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} does not have a defined parameter grid.\")\n",
    "\n",
    "    # Broad Grid Search\n",
    "    broad_search = GridSearchCV(model, broad_param_grid, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    broad_search.fit(X_train, y_train)\n",
    "    best_params_broad = broad_search.best_params_\n",
    "\n",
    "    # Define refined grid based on broad search results\n",
    "    if model_name in [\"Logistic Regression\", \"Lasso (L1)\", \"ElasticNet (L1+L2)\", \"SVM (Linear)\"]:\n",
    "        refined_grid = {'C': np.linspace(best_params_broad['C'] * 0.1, best_params_broad['C'] * 10, 5)}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        refined_grid = {\n",
    "            'n_estimators': [max(10, best_params_broad['n_estimators'] - 50), best_params_broad['n_estimators'], best_params_broad['n_estimators'] + 50],\n",
    "            'max_depth': [None] if not best_params_broad['max_depth'] else [\n",
    "                max(1, best_params_broad['max_depth'] - 5), best_params_broad['max_depth'], best_params_broad['max_depth'] + 5]\n",
    "        }\n",
    "    elif model_name == \"Perceptron\":\n",
    "        refined_grid = {'alpha': np.linspace(best_params_broad['alpha'] * 0.1, best_params_broad['alpha'] * 10, 5)}\n",
    "    elif model_name == \"LDA\":\n",
    "        refined_grid = {'shrinkage': [best_params_broad['shrinkage']], 'solver': [best_params_broad['solver']]}\n",
    "\n",
    "    # Narrow Grid Search\n",
    "    narrow_search = GridSearchCV(model, refined_grid, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    narrow_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best Parameters (Broad Search): {best_params_broad}\")\n",
    "    print(f\"Best Parameters (Narrow Search): {narrow_search.best_params_}\")\n",
    "\n",
    "    best_model = narrow_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Train and evaluate final model\n",
    "def train_and_evaluate_final_model(X_train, y_train, X_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Train and evaluate the final model. Reports accuracy and AUC.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Features for training.\n",
    "    - y_train: Labels for training.\n",
    "    - X_test: Features for testing.\n",
    "    - y_test: Labels for testing.\n",
    "    - model: Machine learning model (must support `fit` and `predict_proba`).\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained model.\n",
    "    - test_accuracy: Accuracy on the test set.\n",
    "    - test_auc: AUC score on the test set.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    # Predict probabilities for AUC computation\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "        test_auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"Test Set AUC (Final Model): {test_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"Model does not support probability predictions; skipping AUC computation.\")\n",
    "        test_auc = None\n",
    "\n",
    "    print(f\"Test Set Accuracy (Final Model): {test_accuracy:.4f}\")\n",
    "    return model, test_accuracy, test_auc\n",
    "\n",
    "\n",
    "\n",
    "# Cosine similarity between two models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def calculate_model_similarity(model1, model2):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between two models using cosine similarity or feature importances.\n",
    "\n",
    "    Parameters:\n",
    "    - model1: First trained model\n",
    "    - model2: Second trained model\n",
    "\n",
    "    Returns:\n",
    "    - similarity: Cosine similarity score between the two models' coefficients or importances.\n",
    "    \"\"\"\n",
    "    # Extract the weights (coefficients) or feature importances\n",
    "    def get_model_vector(model):\n",
    "        if hasattr(model, 'coef_'):  # Linear models with coefficients\n",
    "            return model.coef_.flatten()\n",
    "        elif hasattr(model, 'feature_importances_'):  # Tree-based models\n",
    "            return model.feature_importances_\n",
    "        else:\n",
    "            raise ValueError(f\"Model of type {type(model)} does not have coefficients or feature importances.\")\n",
    "    \n",
    "    try:\n",
    "        # Get vectors for the two models\n",
    "        vector1 = get_model_vector(model1)\n",
    "        vector2 = get_model_vector(model2)\n",
    "\n",
    "        # Ensure vectors are of the same length\n",
    "        if len(vector1) != len(vector2):\n",
    "            raise ValueError(\"Model vectors have different lengths. Ensure the models were trained on the same features.\")\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([vector1], [vector2])\n",
    "        return similarity[0][0]  # Return the scalar similarity value\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in calculating similarity: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Full pipeline\n",
    "def pipeline1(X, y, n_features):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    selected_features = feature_selection_with_rfe(X_train, y_train, n_features, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "def pipeline2(X, y):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    \n",
    "    selected_features, features_number = feature_selection_with_rfe_cv(X_train, y_train, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "# Compare CAD and PAD models\n",
    "def compare_models_and_analyze_topography1(X_data_set1, y_data_set1, X_data_set2, y_data_set2, n_features):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline1(X_data_set1, y_data_set1, n_features)\n",
    "    X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    \n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline1(X_data_set2, y_data_set2, n_features)\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set2]\n",
    "    y_pred2 = final_model_data_set2.predict(X_data_set2_selected)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred2))\n",
    "    \n",
    "\n",
    "    print(\"\\nEvaluating data_set1 model on data_set2 dataset:\")\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity\n",
    "\n",
    "def compare_models_and_analyze_topography2(X_data_set1, y_data_set1, X_data_set2, y_data_set2):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline2(X_data_set1, y_data_set1)\n",
    "    X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    \n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline2(X_data_set2, y_data_set2)\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set2]\n",
    "    y_pred2 = final_model_data_set2.predict(X_data_set2_selected)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred2))\n",
    "    \n",
    "\n",
    "    print(\"\\nEvaluating data_set1 model on data_set2 dataset:\")\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity"
   ],
   "id": "53f841406272c9d6",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T22:54:26.239221Z",
     "start_time": "2024-12-16T22:54:26.237612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define user inputs\n",
    "user_dir = \"/Users/xiaoqianxiao\"\n",
    "project_name = \"UKB\"\n",
    "session_ID = 2  # Specify session"
   ],
   "id": "d5f513afe68162b6",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run the pipeline\n",
    "data_set = \"past_anxiety\"  # Dataset identifier\n",
    "X_pad, df_PAD = process_fMRI_data(data_set, user_dir, project_name, session_ID)\n",
    "y_pad = df_PAD[\"hospital_not_now\"]\n",
    "y_pad_GAD7 = df_PAD[\"GAD7_score\"]\n",
    "\n",
    "data_set = \"current_anxiety\"  # Dataset identifier\n",
    "X_cad, df_CAD = process_fMRI_data(data_set, user_dir, project_name, session_ID)\n",
    "y_cad = df_CAD[\"hospital_current_anxiety\"]\n",
    "y_cad_GAD7 = df_CAD[\"GAD7_score\"]"
   ],
   "id": "7c87ad9ae46101af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T22:55:07.311912Z",
     "start_time": "2024-12-16T22:55:07.308268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'n(cad)/(cad_control): {sum(y_cad==True)}/{sum(y_cad==False)} = {((sum(y_cad==True))/(sum(y_cad==False))):.2f}')\n",
    "print(f'n(pad)/(pad_control): {sum(y_pad==True)}/{sum(y_pad==False)} = {((sum(y_pad==True))/(sum(y_pad==False))):.2f}')"
   ],
   "id": "48b294ec0ab1a0b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n(cad)/(cad_control): 118/104 = 1.13\n",
      "n(pad)/(pad_control): 510/476 = 1.07\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_features = 10\n",
    "compare_models_and_analyze_topography1(X_cad, y_cad, X_pad, y_pad, n_features)"
   ],
   "id": "7d44a473ed510380"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models_and_analyze_topography2(X_cad, y_cad, X_pad, y_pad)",
   "id": "e71b2ab503d6e87f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_set = \"ah\"  # Dataset identifier\n",
    "X_ah, df_ah = process_fMRI_data(data_set, user_dir, project_name, session_ID)\n",
    "y_ah = df_ah[\"active_history\"]\n",
    "\n",
    "data_set = \"ih\"  # Dataset identifier\n",
    "X_ih, df_ih = process_fMRI_data(data_set, user_dir, project_name, session_ID)\n",
    "y_ih = df_ih[\"inactive_history\"]\n",
    "\n",
    "data_set = \"a_noh\"  # Dataset identifier\n",
    "X_a_noh, df_a_noh = process_fMRI_data(data_set, user_dir, project_name, session_ID)\n",
    "y_a_noh = df_a_noh[\"active_no_history\"]"
   ],
   "id": "9264d66afb19a8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f'n(ah)/(ah_control): {sum(y_ah==True)}/{sum(y_ah==False)} = {((sum(y_ah==True))/(sum(y_ah==False))):.2f}')\n",
    "print(f'n(ih)/(ih_control): {sum(y_ih==True)}/{sum(y_ih==False)} = {((sum(y_ih==True))/(sum(y_ih==False))):.2f}')\n",
    "print(f'n(a_noh)/(a_noh_control): {sum(y_a_noh==True)}/{sum(y_a_noh==False)} = {((sum(y_a_noh==True))/(sum(y_a_noh==False))):.2f}')"
   ],
   "id": "a6bdaa8ab3fb73cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_features = 20\n",
    "compare_models_and_analyze_topography1(X_ah, y_ah, X_ih, y_ih, n_features)"
   ],
   "id": "5bef5d481f507598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models_and_analyze_topography2(X_ah, y_ah, X_ih, y_ih)",
   "id": "ee7da498c3c43144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_features = 20\n",
    "compare_models_and_analyze_topography1(X_ah, y_ah, X_a_noh, y_a_noh, n_features)"
   ],
   "id": "7f4228ebc9930643"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models_and_analyze_topography2(X_ah, y_ah, X_a_noh, y_a_noh)",
   "id": "5f8b5457f6aa1b45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
